{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2862ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn.decoding import Decoder\n",
    "from nilearn.image import load_img\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIDS_ROOT = Path(r\"C:/Users/duart/Desktop/Tese/Mapping_Tese/mapping_tese/data/BIDS-somatosensory/BIDS-somatosensory\")\n",
    "DERIVATIVES = BIDS_ROOT / \"derivatives\" / \"fmriprep\"\n",
    "\n",
    "\n",
    "subject = \"sub-p0001\"\n",
    "session = \"ses-01\"\n",
    "task = \"task-S1Map\"\n",
    "space = \"MNI152NLin2009cAsym\"\n",
    "\n",
    "n_runs = 4\n",
    "TR = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23112b",
   "metadata": {},
   "source": [
    "### Event files all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b132d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = []\n",
    "for run in range(1, n_runs + 1):\n",
    "    events_path = BIDS_ROOT / subject / session / \"func\" / f\"{subject}_{session}_{task}_run-{run}_events.tsv\"\n",
    "    events = pd.read_csv(events_path, sep='\\t')\n",
    "    events['run'] = run\n",
    "    all_events.append(events)\n",
    "\n",
    "events_df = pd.concat(all_events, ignore_index=True)\n",
    "\n",
    "# remove Baseline and Jitter\n",
    "stim_events = events_df[~events_df['trial_type'].isin(['Baseline', 'Jitter'])].copy()\n",
    "\n",
    "print(f\"Total events loaded: {len(events_df)}\")\n",
    "print(f\"Stimulation events: {len(stim_events)}\")\n",
    "print(f\"Unique conditions: {stim_events['trial_type'].nunique()}\")\n",
    "print(f\"\\nConditions: {sorted(stim_events['trial_type'].unique())}\")\n",
    "print(f\"\\nSamples per condition:\")\n",
    "print(stim_events['trial_type'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img, mean_img, concat_imgs\n",
    "from nilearn.image import load_img\n",
    "\n",
    "HRF_DELAY = 5.0\n",
    "WINDOW = 2\n",
    "\n",
    "sample_imgs = []\n",
    "labels = []\n",
    "\n",
    "for run in range(1, n_runs + 1):\n",
    "\n",
    "    func_path = (DERIVATIVES / subject / session / \"func\" /\n",
    "                 f\"{subject}_{session}_{task}_run-{run}_space-{space}_desc-preproc_bold.nii.gz\")\n",
    "\n",
    "    img = load_img(str(func_path))\n",
    "    run_events = stim_events[stim_events['run'] == run]\n",
    "\n",
    "    run_length = img.shape[3]\n",
    "\n",
    "    print(f\"Run {run} loaded: {img.shape}\")\n",
    "\n",
    "    for _, event in run_events.iterrows():\n",
    "\n",
    "        peak_volume = int((event['onset'] + HRF_DELAY) / TR)\n",
    "        if peak_volume >= run_length:\n",
    "            continue\n",
    "\n",
    "        vols = list(range(max(0, peak_volume-WINDOW),\n",
    "                          min(run_length, peak_volume+WINDOW+1)))\n",
    "\n",
    "        window_img = index_img(img, vols)\n",
    "        averaged = mean_img(window_img)\n",
    "\n",
    "        sample_imgs.append(averaged)\n",
    "        labels.append(event['trial_type'])\n",
    "\n",
    "# build final dataset (small!)\n",
    "X = concat_imgs(sample_imgs)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"\\nFinal dataset shape:\", X.shape)\n",
    "print(\"Samples:\", len(y))\n",
    "print(\"Classes:\", len(np.unique(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain mask from first run -> all the same in MNI space\n",
    "mask_path = (DERIVATIVES / subject / session / \"func\" / \n",
    "             f\"{subject}_{session}_{task}_run-1_space-{space}_desc-brain_mask.nii.gz\")\n",
    "mask_img = load_img(str(mask_path))\n",
    "\n",
    "print(f\"Mask shape: {mask_img.shape}\")\n",
    "print(f\"Mask loaded: {mask_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d92e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import load_img, index_img, mean_img\n",
    "\n",
    "HRF_DELAY = 5.0   # seconds\n",
    "WINDOW = 2        # ±2 volumes\n",
    "\n",
    "sample_imgs = []\n",
    "labels = []\n",
    "\n",
    "for run in range(1, n_runs + 1):\n",
    "\n",
    "    func_path = (DERIVATIVES / subject / session / \"func\" /\n",
    "                 f\"{subject}_{session}_{task}_run-{run}_space-{space}_desc-preproc_bold.nii.gz\")\n",
    "\n",
    "    img = load_img(str(func_path))\n",
    "    run_events = stim_events[stim_events['run'] == run]\n",
    "    run_length = img.shape[3]\n",
    "\n",
    "    print(f\"Run {run}: {img.shape}\")\n",
    "\n",
    "    for _, event in run_events.iterrows():\n",
    "\n",
    "        # HRF peak timing\n",
    "        peak_volume = int((event['onset'] + HRF_DELAY) / TR)\n",
    "\n",
    "        if peak_volume >= run_length:\n",
    "            continue\n",
    "\n",
    "        # temporal averaging window\n",
    "        vols = list(range(max(0, peak_volume-WINDOW),\n",
    "                          min(run_length, peak_volume+WINDOW+1)))\n",
    "\n",
    "        window_img = index_img(img, vols)\n",
    "        averaged_img = mean_img(window_img)\n",
    "\n",
    "        sample_imgs.append(averaged_img)\n",
    "        labels.append(event['trial_type'])\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"\\nTotal samples: {len(y)}\")\n",
    "print(f\"Unique labels: {len(np.unique(y))}\")\n",
    "print(f\"Labels: {np.unique(y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs\n",
    "\n",
    "X = concat_imgs(sample_imgs)\n",
    "\n",
    "print(\"Final dataset shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Cross-validation: Stratified 5-fold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "from nilearn.image import math_img\n",
    "\n",
    "atlas = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "s1_index = atlas.labels.index('Postcentral Gyrus')\n",
    "s1_mask = math_img(f\"img == {s1_index}\", img=atlas.maps)\n",
    "print(\"S1 mask created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(\n",
    "    estimator='svc',           \n",
    "    mask=s1_mask,             \n",
    "    standardize='zscore_sample',  \n",
    "    screening_percentile=20,   \n",
    "    cv=cv,                     \n",
    "    n_jobs=-1  ,\n",
    "    scoring='accuracy',             \n",
    ")\n",
    "\n",
    "decoder.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea60db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = decoder.cv_scores_\n",
    "\n",
    "# Calculate statistics\n",
    "n_conditions = len(np.unique(y))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DECODING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAccuracy per fold:\")\n",
    "for fold, (condition, scores) in enumerate(cv_scores.items(), 1):\n",
    "    print(f\"  Fold {fold}: {np.mean(scores):.3f}\")\n",
    "\n",
    "all_scores = np.concatenate([scores for scores in cv_scores.values()])\n",
    "mean_accuracy = np.mean(all_scores)\n",
    "std_accuracy = np.std(all_scores)\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n",
    "\n",
    "print(f\"Performance:   {mean_accuracy*100:.1f}%\")\n",
    "print(f\"{'=' * 70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "fold_scores = [np.mean(scores) for scores in cv_scores.values()]\n",
    "folds = range(1, len(fold_scores) + 1)\n",
    "\n",
    "ax.bar(folds, fold_scores, color='steelblue', alpha=0.7, edgecolor='black', label='Fold accuracy')\n",
    "ax.axhline(y=mean_accuracy, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_accuracy:.3f}')\n",
    "\n",
    "ax.set_xlabel('Fold (Run Left Out)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Cross-Validation Decoding Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(folds)\n",
    "ax.set_ylim([0, max(fold_scores) * 1.2])\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "coef_img = decoder.coef_img_['E1'] \n",
    "weight_imgs = [decoder.coef_img_[condition] for condition in np.unique(y)]\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plotting.plot_stat_map(\n",
    "    coef_img,\n",
    "    title=f'Feature Weights - Condition E1',\n",
    "    cut_coords=5,\n",
    "    display_mode='z',\n",
    "    cmap='cold_hot',\n",
    "    figure=fig\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "n_conditions = len(np.unique(y))\n",
    "chance_level = 1.0 / n_conditions\n",
    "total_samples = len(y)\n",
    "correct_predictions = int(mean_accuracy * total_samples)\n",
    "\n",
    "#H0 = random classification at chance level\n",
    "p_value = binomtest(correct_predictions, total_samples, chance_level, alternative='greater')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nChance level (1/n_conditions): {chance_level:.3f} ({chance_level*100:.1f}%)\")\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Observed correct predictions: {correct_predictions}\")\n",
    "print(f\"Expected correct predictions (chance): {int(total_samples * chance_level)}\")\n",
    "print(f\"\\nBinomial Test (one-tailed, greater than chance):\")\n",
    "print(f\"  p-value: {p_value.pvalue:.2e}\")\n",
    "if p_value.pvalue < 0.001:\n",
    "    print(f\"  Result: Significantly above chance (p < 0.001) ***\")\n",
    "elif p_value.pvalue < 0.05:\n",
    "    print(f\"  Result: Significantly above chance (p < 0.05) *\")\n",
    "else:\n",
    "    print(f\"  Result: Not significantly above chance (p = {p_value.pvalue:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c14b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# images->voxel features\n",
    "X_features = decoder.masker_.transform(X)\n",
    "clf = SVC(kernel='linear')\n",
    "y_pred = np.zeros_like(y, dtype=object)\n",
    "\n",
    "for train, test in cv.split(X_features, y):\n",
    "    model = clone(clf)\n",
    "    model.fit(X_features[train], y[train])\n",
    "    y_pred[test] = model.predict(X_features[test])\n",
    "\n",
    "conditions = np.unique(y)\n",
    "cm = confusion_matrix(y, y_pred, labels=conditions)\n",
    "per_condition_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PER-CONDITION ACCURACY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    acc = per_condition_accuracy[i]\n",
    "    samples = cm[i].sum()\n",
    "    print(f\"{condition}: {acc:.3f} ({acc*100:.1f}%) - {samples} samples\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y, y_pred):.3f}\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "\n",
    "ax.set_xticks(np.arange(len(conditions)))\n",
    "ax.set_yticks(np.arange(len(conditions)))\n",
    "ax.set_xticklabels(conditions, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conditions)\n",
    "\n",
    "ax.set_xlabel('Predicted Condition', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Condition', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Confusion Matrix - Somatotopic Decoding', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(len(conditions)):\n",
    "    for j in range(len(conditions)):\n",
    "        text = ax.text(j, i, cm[i, j],\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Number of Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a88bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask, unmask\n",
    "\n",
    "cov = np.cov(X_features, rowvar=False)\n",
    "pattern_imgs = {}\n",
    "for condition, weight_img in decoder.coef_img_.items():\n",
    "    w = apply_mask(weight_img, decoder.mask_img_)\n",
    "    pattern = cov @ w #-> Haufe et al. (2014) transformation to get activation patterns\n",
    "    pattern_imgs[condition] = unmask(pattern, decoder.mask_img_)\n",
    "\n",
    "# subset of conditions to visualize (first 6)\n",
    "n_to_plot = min(6, len(conditions))\n",
    "selected_conditions = conditions[:n_to_plot]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, condition in enumerate(selected_conditions):\n",
    "    ax = axes[idx]\n",
    "    coef_img = pattern_imgs[condition]\n",
    "    vmax = np.percentile(np.abs(apply_mask(list(pattern_imgs.values()), decoder.mask_img_)), 99)\n",
    "    \n",
    "    plotting.plot_stat_map(\n",
    "        coef_img,\n",
    "        title=f'Pattern - {condition}',\n",
    "        cut_coords=3,\n",
    "        display_mode='z',\n",
    "        cmap='RdBu_r',\n",
    "        figure=fig,\n",
    "        axes=ax,\n",
    "        colorbar=False,\n",
    "        threshold=None,\n",
    "        vmax=vmax,\n",
    "        symmetric_cbar=True,\n",
    "    )\n",
    "\n",
    "for idx in range(n_to_plot, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Somatotopic Activation Patterns for Selected Conditions (Haufe-transformed)', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check weight statistics and thresholding\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEIGHT STATISTICS FOR EACH CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition in conditions[:5]:\n",
    "    coef_img = decoder.coef_img_[condition]\n",
    "    coef_data = coef_img.get_fdata()\n",
    "    print(f\"\\n{condition}:\")\n",
    "    print(f\"  Min weight: {coef_data.min():.4f}\")\n",
    "    print(f\"  Max weight: {coef_data.max():.4f}\")\n",
    "    print(f\"  Mean weight: {coef_data.mean():.4f}\")\n",
    "    print(f\"  Std weight: {coef_data.std():.4f}\")\n",
    "    print(f\"  Voxels with |weight| > 0.1: {np.sum(np.abs(coef_data) > 0.1)}\")\n",
    "    print(f\"  Voxels with |weight| > 0.5: {np.sum(np.abs(coef_data) > 0.5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36056230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anatomical reference image for better localization\n",
    "anat_path = (DERIVATIVES / subject / session / \"anat\" / \n",
    "             f\"{subject}_{session}_space-{space}_desc-preproc_T1w.nii.gz\")\n",
    "anat_img = load_img(str(anat_path))\n",
    "print(f\"Anatomical image loaded: {anat_path.name}\")\n",
    "print(f\"Shape: {anat_img.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved weight visualization with anatomical reference and thresholding\n",
    "# Plot with thresholding to highlight significant weights\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "threshold_percentile = 90\n",
    "\n",
    "for idx, condition in enumerate(selected_conditions):\n",
    "    ax = axes[idx]\n",
    "    coef_img = decoder.coef_img_[condition]\n",
    "    coef_data = coef_img.get_fdata()\n",
    "    abs_weights = np.abs(coef_data)\n",
    "    threshold = np.percentile(abs_weights[abs_weights > 0], threshold_percentile)\n",
    "    \n",
    "    plotting.plot_stat_map(\n",
    "        coef_img,\n",
    "        bg_img=anat_img, \n",
    "        title=f'Weights - {condition}\\n(threshold: {threshold:.4f})',\n",
    "        cut_coords=[0, -25, 5],  # central region, include postcentral area\n",
    "        display_mode='ortho',  # multiple views\n",
    "        cmap='RdBu_r',\n",
    "        figure=fig,\n",
    "        axes=ax,\n",
    "        colorbar=True,\n",
    "        threshold=threshold\n",
    "    )\n",
    "\n",
    "for idx in range(n_to_plot, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle(f'Classifier Weights with Anatomical Reference\\n(90th percentile threshold)', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Thresholded visualization with anatomical background:\")\n",
    "print(f\"Using 90th percentile of absolute weights to highlight significant activations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import find_objects, label\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PEAK ACTIVATION LOCATIONS (MNI COORDINATES)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition in conditions[:5]:\n",
    "    coef_img = decoder.coef_img_[condition]\n",
    "    coef_data = coef_img.get_fdata()\n",
    "    affine = coef_img.affine\n",
    "    \n",
    "    # Find voxels in the top 5% of absolute weights\n",
    "    abs_weights = np.abs(coef_data)\n",
    "    threshold = np.percentile(abs_weights[abs_weights > 0], 95)\n",
    "    mask = abs_weights > threshold\n",
    "    \n",
    "    if np.sum(mask) > 0:\n",
    "        coords = np.where(mask)\n",
    "        peak_idx = np.argmax(abs_weights[mask])\n",
    "        peak_voxel = (coords[0][peak_idx], coords[1][peak_idx], coords[2][peak_idx])\n",
    "        \n",
    "        # Convert voxel to MNI coordinates\n",
    "        peak_mni = affine @ np.array([peak_voxel[0], peak_voxel[1], peak_voxel[2], 1])\n",
    "        \n",
    "        print(f\"\\n{condition}:\")\n",
    "        print(f\"  Peak voxel (array coords): {peak_voxel}\")\n",
    "        print(f\"  Peak MNI coords: x={peak_mni[0]:.1f}, y={peak_mni[1]:.1f}, z={peak_mni[2]:.1f}\")\n",
    "        print(f\"  Peak weight value: {coef_data[peak_voxel]:.4f}\")\n",
    "        print(f\"  Number of suprathreshold voxels: {np.sum(mask)}\")\n",
    "        \n",
    "        x_mni = peak_mni[0]\n",
    "        if x_mni < -5:\n",
    "            hemisphere = \"LEFT\"\n",
    "        elif x_mni > 5:\n",
    "            hemisphere = \"RIGHT\"\n",
    "        else:\n",
    "            hemisphere = \"MIDLINE\"\n",
    "        print(f\"  Hemisphere: {hemisphere}\")\n",
    "    else:\n",
    "        print(f\"\\n{condition}: No significant weights found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fold_scores = [np.mean(scores) for scores in cv_scores.values()]\n",
    "ax = axes[0]\n",
    "ax.bar(range(1, len(fold_scores) + 1), fold_scores, \n",
    "       color='steelblue', alpha=0.7, edgecolor='black', label='Fold accuracy')\n",
    "ax.axhline(y=mean_accuracy, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {mean_accuracy:.3f}')\n",
    "ax.axhline(y=chance_level, color='gray', linestyle=':', linewidth=2, \n",
    "           label=f'Chance: {chance_level:.3f}')\n",
    "ax.set_xlabel('Cross-Validation Fold (Run Left Out)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "ax.set_title('CV Fold Stability', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(range(1, len(fold_scores) + 1))\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "fold_scores_array = np.array(fold_scores)\n",
    "stats_data = {\n",
    "    'Mean': mean_accuracy,\n",
    "    'Std Dev': std_accuracy,\n",
    "    'Min': np.min(fold_scores_array),\n",
    "    'Max': np.max(fold_scores_array),\n",
    "    'Range': np.max(fold_scores_array) - np.min(fold_scores_array)\n",
    "}\n",
    "\n",
    "y_pos = np.arange(len(stats_data))\n",
    "values = list(stats_data.values())\n",
    "colors_stats = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "bars = ax.barh(y_pos, values, color=colors_stats, alpha=0.7, edgecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(list(stats_data.keys()))\n",
    "ax.set_xlabel('Value', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Cross-Validation Performance Statistics', fontsize=12, fontweight='bold')\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars, values)):\n",
    "    ax.text(value, bar.get_y() + bar.get_height()/2, f'{value:.3f}', \n",
    "            ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CROSS-VALIDATION STABILITY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mean Accuracy:        {mean_accuracy:.3f}\")\n",
    "print(f\"Standard Deviation:   {std_accuracy:.3f}\")\n",
    "print(f\"Min Accuracy:         {np.min(fold_scores_array):.3f}\")\n",
    "print(f\"Max Accuracy:         {np.max(fold_scores_array):.3f}\")\n",
    "print(f\"Range:                {np.max(fold_scores_array) - np.min(fold_scores_array):.3f}\")\n",
    "print(f\"Coefficient of Variation: {std_accuracy / mean_accuracy:.3f}\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddd523",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECODING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nParticipant: {subject}, Session: {session}\")\n",
    "print(f\"Task: {task}\")\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(f\"Number of electrodes (conditions): {n_conditions}\")\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"\\nCLASSIFIER SETUP:\")\n",
    "print(f\"  Model: Support Vector Classifier (Linear kernel)\")\n",
    "print(f\"  Feature standardization: Z-score normalization\")\n",
    "print(f\"  Feature selection: 20th percentile screening\")\n",
    "print(f\"  Cross-validation: Leave-One-Group-Out (by run)\")\n",
    "print(f\"\\nRESULTS:\")\n",
    "print(f\"  Mean Decoding Accuracy: {mean_accuracy:.3f} ({mean_accuracy*100:.1f}%)\")\n",
    "print(f\"  Chance Level: {chance_level:.3f} ({chance_level*100:.1f}%)\")\n",
    "print(f\"  Statistical Significance: p < 0.001 ***\" if p_value.pvalue < 0.001 else f\"  Statistical Significance: p = {p_value.pvalue:.3f}\")\n",
    "print(f\"  Balanced Accuracy: {balanced_accuracy_score(y, y_pred):.3f}\")\n",
    "print(f\"\\nCONSISTENCY:\")\n",
    "print(f\"  Std Dev (CV folds): {std_accuracy:.3f}\")\n",
    "print(f\"  Min Fold Accuracy: {np.min(np.array(fold_scores)):.3f}\")\n",
    "print(f\"  Max Fold Accuracy: {np.max(np.array(fold_scores)):.3f}\")\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "if mean_accuracy > (0.5 * chance_level):\n",
    "    if p_value.pvalue < 0.001:\n",
    "        print(f\"  ✓ Electrode-specific activations are highly decodable from fMRI\")\n",
    "    elif p_value.pvalue < 0.05:\n",
    "        print(f\"  ✓ Electrode-specific activations are significantly decodable from fMRI\")\n",
    "    else:\n",
    "        print(f\"  • Moderate decodability, but not statistically significant\")\n",
    "else:\n",
    "    print(f\"  • Poor decodability; performance near chance level\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "somatosensory_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
