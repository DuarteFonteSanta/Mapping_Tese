{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2862ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.decoding import Decoder\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIDS_ROOT = Path(r\"C:/Users/duart/Desktop/Tese/Mapping_Tese/mapping_tese/data/BIDS-somatosensory/BIDS-somatosensory\")\n",
    "DERIVATIVES = BIDS_ROOT / \"derivatives\" / \"fmriprep\"\n",
    "\n",
    "\n",
    "subject = \"sub-p0001\"\n",
    "session = \"ses-01\"\n",
    "task = \"task-S1Map\"\n",
    "space = \"MNI152NLin2009cAsym\"\n",
    "\n",
    "n_runs = 4\n",
    "TR = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "FIGURES_DIR = RESULTS_DIR / \"figures\"\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_LOG = RESULTS_DIR / \"outputs.txt\"\n",
    "log_file = open(OUTPUT_LOG, 'w', encoding='utf-8')\n",
    "\n",
    "original_print = print\n",
    "def print(*args, **kwargs):\n",
    "    original_print(*args, **kwargs)\n",
    "    original_print(*args, **kwargs, file=log_file, flush=True)\n",
    "\n",
    "print(f\"Results will be saved to: {RESULTS_DIR.resolve()}\")\n",
    "print(f\"Figures directory: {FIGURES_DIR.resolve()}\")\n",
    "print(f\"Output log: {OUTPUT_LOG.resolve()}\")\n",
    "print(f\"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Random seed (numpy): {RANDOM_SEED}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23112b",
   "metadata": {},
   "source": [
    "### Event files all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b132d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = []\n",
    "for run in range(1, n_runs + 1):\n",
    "    events_path = BIDS_ROOT / subject / session / \"func\" / f\"{subject}_{session}_{task}_run-{run}_events.tsv\"\n",
    "    events = pd.read_csv(events_path, sep='\\t')\n",
    "    events['run'] = run\n",
    "    all_events.append(events)\n",
    "\n",
    "events_df = pd.concat(all_events, ignore_index=True)\n",
    "\n",
    "# remove Baseline and Jitter\n",
    "stim_events = events_df[~events_df['trial_type'].isin(['Baseline', 'Jitter'])].copy()\n",
    "\n",
    "print(f\"Total events loaded: {len(events_df)}\")\n",
    "print(f\"Stimulation events: {len(stim_events)}\")\n",
    "print(f\"Unique conditions: {stim_events['trial_type'].nunique()}\")\n",
    "print(f\"\\nConditions: {sorted(stim_events['trial_type'].unique())}\")\n",
    "print(f\"\\nSamples per condition:\")\n",
    "print(stim_events['trial_type'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img, mean_img, concat_imgs\n",
    "from nilearn.image import load_img\n",
    "\n",
    "HRF_DELAY = 5.0\n",
    "WINDOW = 2\n",
    "\n",
    "sample_imgs = []\n",
    "labels = []\n",
    "groups = [] \n",
    "\n",
    "for run in range(1, n_runs + 1):\n",
    "\n",
    "    func_path = (DERIVATIVES / subject / session / \"func\" /\n",
    "                 f\"{subject}_{session}_{task}_run-{run}_space-{space}_desc-preproc_bold.nii.gz\")\n",
    "\n",
    "    img = load_img(str(func_path))\n",
    "    run_events = stim_events[stim_events['run'] == run].sort_values('onset')\n",
    "\n",
    "    run_length = img.shape[3]\n",
    "\n",
    "    print(f\"Run {run} loaded: {img.shape}\")\n",
    "\n",
    "    for _, event in run_events.iterrows():\n",
    "\n",
    "        peak_volume = int(round((event['onset'] + HRF_DELAY) / TR))\n",
    "        if peak_volume >= run_length:\n",
    "            continue\n",
    "\n",
    "        vols = list(range(max(0, peak_volume-WINDOW),\n",
    "                          min(run_length, peak_volume+WINDOW+1)))\n",
    "\n",
    "        window_img = index_img(img, vols)\n",
    "        averaged = mean_img(window_img)\n",
    "\n",
    "        sample_imgs.append(averaged)\n",
    "        labels.append(event['trial_type'])\n",
    "        groups.append(run)\n",
    "\n",
    "X = concat_imgs(sample_imgs)\n",
    "y = np.array(labels)\n",
    "groups = np.array(groups)\n",
    "\n",
    "print(\"\\nFinal dataset shape:\", X.shape)\n",
    "print(\"Samples:\", len(y))\n",
    "print(\"Classes:\", len(np.unique(y)))\n",
    "print(\"Runs:\", np.unique(groups))\n",
    "print(\"Samples per run:\")\n",
    "print(pd.Series(groups).value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_fold = groups - 1 \n",
    "cv = PredefinedSplit(test_fold)\n",
    "print(f\"Cross-validation: Leave-one-run-out (n_folds={cv.get_n_splits()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "from nilearn.image import new_img_like\n",
    "\n",
    "atlas = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "s1_indices = [i for i, lab in enumerate(atlas.labels) if 'Postcentral Gyrus' in str(lab) and i != 0]\n",
    "if len(s1_indices) == 0:\n",
    "    s1_index = atlas.labels.index('Postcentral Gyrus')\n",
    "    s1_indices = [s1_index]\n",
    "\n",
    "atlas_img = atlas.maps\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "mask_data = np.isin(atlas_data, s1_indices).astype('uint8')\n",
    "s1_mask = new_img_like(atlas_img, mask_data)\n",
    "\n",
    "print(f\"S1 mask created from atlas indices: {s1_indices}\")\n",
    "print(\"Selected labels:\")\n",
    "for i in s1_indices:\n",
    "    print(f\"  - {atlas.labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(\n",
    "    estimator='svc',           \n",
    "    mask=s1_mask,             \n",
    "    standardize='zscore_sample',  \n",
    "    screening_percentile=20,   \n",
    "    cv=cv,                     \n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "decoder.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea60db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "\n",
    "y_pred_cv = np.empty_like(y, dtype=object)\n",
    "fold_scores = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DECODING RESULTS (Leave-one-run-out CV)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for fold_i, (train_idx, test_idx) in enumerate(cv.split(np.zeros(len(y))), 1):\n",
    "    left_out_run = np.unique(groups[test_idx])\n",
    "    left_out_run = int(left_out_run[0]) if len(left_out_run) == 1 else left_out_run\n",
    "\n",
    "    X_train = index_img(X, train_idx)\n",
    "    X_test = index_img(X, test_idx)\n",
    "    \n",
    "    decoder_fold = Decoder(\n",
    "        estimator='svc',\n",
    "        mask=s1_mask,\n",
    "        standardize='zscore_sample',\n",
    "        screening_percentile=20,\n",
    "        cv=None,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy',\n",
    "    )\n",
    "\n",
    "    decoder_fold.fit(X_train, y[train_idx])\n",
    "    y_pred_cv[test_idx] = decoder_fold.predict(X_test)\n",
    "\n",
    "    fold_acc = np.mean(y_pred_cv[test_idx] == y[test_idx])\n",
    "    fold_scores.append(fold_acc)\n",
    "\n",
    "    print(f\"  Fold {fold_i} (left-out run {left_out_run}): {fold_acc:.3f}\")\n",
    "\n",
    "fold_scores = np.array(fold_scores)\n",
    "mean_accuracy = float(np.mean(fold_scores))\n",
    "std_accuracy = float(np.std(fold_scores))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n",
    "print(f\"Performance:   {mean_accuracy*100:.1f}%\")\n",
    "print(f\"{'=' * 70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "folds = range(1, len(fold_scores) + 1)\n",
    "\n",
    "ax.bar(folds, fold_scores, color='steelblue', alpha=0.7, edgecolor='black', label='Fold accuracy')\n",
    "ax.axhline(y=mean_accuracy, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_accuracy:.3f}')\n",
    "\n",
    "ax.set_xlabel('CV Fold (Left-out run)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Leave-One-Run-Out Decoding Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(list(folds))\n",
    "ax.set_ylim([0, max(fold_scores) * 1.2])\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'fold_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "first_condition = list(decoder.coef_img_.keys())[0]\n",
    "coef_img = decoder.coef_img_[first_condition]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plotting.plot_stat_map(\n",
    "    coef_img,\n",
    "    title=f'Feature Weights - Condition {first_condition}',\n",
    "    cut_coords=5,\n",
    "    display_mode='z',\n",
    "    cmap='cold_hot',\n",
    "    figure=fig\n",
    ")\n",
    "\n",
    "fig.savefig(FIGURES_DIR / f'weights_{first_condition}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c14b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "y_pred = y_pred_cv.copy()\n",
    "conditions = np.unique(y)\n",
    "cm = confusion_matrix(y, y_pred, labels=conditions)\n",
    "per_condition_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PER-CONDITION ACCURACY (Out-of-fold CV)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    acc = per_condition_accuracy[i]\n",
    "    samples = cm[i].sum()\n",
    "    print(f\"{condition}: {acc:.3f} ({acc*100:.1f}%) - {samples} samples\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y, y_pred):.3f}\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "\n",
    "ax.set_xticks(np.arange(len(conditions)))\n",
    "ax.set_yticks(np.arange(len(conditions)))\n",
    "ax.set_xticklabels(conditions, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conditions)\n",
    "\n",
    "ax.set_xlabel('Predicted Condition', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Condition', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Confusion Matrix - Somatotopic Decoding (Out-of-fold CV)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(len(conditions)):\n",
    "    for j in range(len(conditions)):\n",
    "        text = ax.text(j, i, cm[i, j],\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Number of Samples')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40319885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "n_conditions = len(np.unique(y))\n",
    "chance_level = 1.0 / n_conditions\n",
    "total_samples = len(y)\n",
    "correct_predictions = int(np.sum(y == y_pred))\n",
    "\n",
    "# H0 = random classification at chance level\n",
    "p_value = binomtest(correct_predictions, total_samples, chance_level, alternative='greater')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING (Out-of-fold CV)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nChance level (1/n_conditions): {chance_level:.3f} ({chance_level*100:.1f}%)\")\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Observed correct predictions: {correct_predictions}\")\n",
    "print(f\"Expected correct predictions (chance): {int(total_samples * chance_level)}\")\n",
    "print(f\"\\nBinomial Test (one-tailed, greater than chance):\")\n",
    "print(f\"  p-value: {p_value.pvalue:.2e}\")\n",
    "\n",
    "if p_value.pvalue < 0.001:\n",
    "    print(\"  Result: Significantly above chance (p < 0.001) ***\")\n",
    "elif p_value.pvalue < 0.05:\n",
    "    print(\"  Result: Significantly above chance (p < 0.05) *\")\n",
    "else:\n",
    "    print(f\"  Result: Not significantly above chance (p = {p_value.pvalue:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a88bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask, unmask\n",
    "\n",
    "\n",
    "X_features = decoder.masker_.transform(X)\n",
    "cov = np.cov(X_features, rowvar=False)\n",
    "pattern_imgs = {}\n",
    "for condition, weight_img in decoder.coef_img_.items():\n",
    "    w = apply_mask(weight_img, decoder.mask_img_)\n",
    "    pattern = cov @ w #-> Haufe et al. (2014) transformation to get activation patterns\n",
    "    pattern_imgs[condition] = unmask(pattern, decoder.mask_img_)\n",
    "\n",
    "# subset of conditions to visualize (first 6)\n",
    "n_to_plot = min(6, len(conditions))\n",
    "selected_conditions = conditions[:n_to_plot]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "vmax = np.percentile(np.abs(apply_mask(list(pattern_imgs.values()), decoder.mask_img_)), 99)\n",
    "for idx, condition in enumerate(selected_conditions):\n",
    "    ax = axes[idx]\n",
    "    coef_img = pattern_imgs[condition]\n",
    "    \n",
    "    plotting.plot_stat_map(\n",
    "        coef_img,\n",
    "        title=f'Pattern - {condition}',\n",
    "        cut_coords=3,\n",
    "        display_mode='z',\n",
    "        cmap='RdBu_r',\n",
    "        figure=fig,\n",
    "        axes=ax,\n",
    "        colorbar=False,\n",
    "        threshold=None,\n",
    "        vmax=vmax,\n",
    "        symmetric_cbar=True,\n",
    "    )\n",
    "\n",
    "for idx in range(n_to_plot, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Somatotopic Activation Patterns for Selected Conditions (Haufe-transformed)', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'activation_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEIGHT STATISTICS FOR EACH CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition in conditions[:5]:\n",
    "    pattern_img = pattern_imgs[condition]\n",
    "    data = pattern_img.get_fdata()\n",
    "    nonzero = data[np.abs(data) > 0]\n",
    "    if len(nonzero) == 0:\n",
    "        print(f\"\\n{condition}: empty map\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{condition}:\")\n",
    "    print(f\"  Min pattern: {nonzero.min():.4f}\")\n",
    "    print(f\"  Max pattern: {nonzero.max():.4f}\")\n",
    "    print(f\"  Mean |pattern|: {np.mean(np.abs(nonzero)):.4f}\")\n",
    "    print(f\"  Std pattern: {nonzero.std():.4f}\")\n",
    "\n",
    "    p95 = np.percentile(np.abs(nonzero), 95)\n",
    "    p99 = np.percentile(np.abs(nonzero), 99)\n",
    "\n",
    "    print(f\"  Voxels > 95th percentile: {np.sum(np.abs(nonzero) > p95)}\")\n",
    "    print(f\"  Voxels > 99th percentile: {np.sum(np.abs(nonzero) > p99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PEAK ACTIVATION LOCATIONS (MNI COORDINATES)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition in conditions[:5]:\n",
    "    img = pattern_imgs[condition]\n",
    "    data = img.get_fdata()\n",
    "    affine = img.affine\n",
    "\n",
    "    nonzero = np.abs(data) > 0\n",
    "    if np.sum(nonzero) == 0:\n",
    "        print(f\"\\n{condition}: empty map\")\n",
    "        continue\n",
    "    \n",
    "    # Find voxels in the top 1% of absolute weights\n",
    "    threshold = np.percentile(np.abs(data[nonzero]),99)\n",
    "    mask = np.abs(data) >= threshold\n",
    "\n",
    "    #remove small clusters\n",
    "    labeled, n = label(mask)\n",
    "    if n == 0:\n",
    "        print(f\"\\n{condition}: no suprathreshold clusters\")\n",
    "        continue\n",
    "    \n",
    "    sizes = [(labeled==i).sum() for i in range(1, n+1)]\n",
    "    largest = np.argmax(sizes) + 1\n",
    "    cluster = labeled == largest\n",
    "\n",
    "    peak_index = np.unravel_index(np.argmax(np.abs(data) * cluster), data.shape)\n",
    "    peak_value = data[peak_index]\n",
    "\n",
    "    #(voxel->MNI)\n",
    "    peak_mni = affine @ np.array([*peak_index,1])\n",
    "    print(f\"\\n{condition}:\")\n",
    "    print(f\"  Peak MNI coords: x={peak_mni[0]:.1f}, y={peak_mni[1]:.1f}, z={peak_mni[2]:.1f}\")\n",
    "    print(f\"  Pattern value: {peak_value:.4f}\")\n",
    "    print(f\"  Cluster size: {cluster.sum()} voxels\")\n",
    "\n",
    "    if peak_mni[0] < -5:\n",
    "        hemisphere = \"LEFT\"\n",
    "\n",
    "    elif peak_mni[0] > 5:\n",
    "        hemisphere = \"RIGHT\"\n",
    "    \n",
    "    else:\n",
    "        hemisphere = \"MID\"\n",
    "    \n",
    "    print(f\"Hemisphere: {hemisphere}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.bar(range(1, len(fold_scores) + 1), fold_scores,\n",
    "       color='steelblue', alpha=0.7, edgecolor='black', label='Fold accuracy')\n",
    "ax.axhline(y=mean_accuracy, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Mean: {mean_accuracy:.3f}')\n",
    "ax.axhline(y=chance_level, color='gray', linestyle=':', linewidth=2,\n",
    "           label=f'Chance: {chance_level:.3f}')\n",
    "ax.set_xlabel('CV Fold (Left-out run)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "ax.set_title('CV Fold Stability', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(range(1, len(fold_scores) + 1))\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "stats_data = {\n",
    "    'Mean': mean_accuracy,\n",
    "    'Std Dev': std_accuracy,\n",
    "    'Min': float(np.min(fold_scores)),\n",
    "    'Max': float(np.max(fold_scores)),\n",
    "    'Range': float(np.max(fold_scores) - np.min(fold_scores))\n",
    "}\n",
    "\n",
    "y_pos = np.arange(len(stats_data))\n",
    "values = list(stats_data.values())\n",
    "colors_stats = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "bars = ax.barh(y_pos, values, color=colors_stats, alpha=0.7, edgecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(list(stats_data.keys()))\n",
    "ax.set_xlabel('Value', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Cross-Validation Performance Statistics', fontsize=12, fontweight='bold')\n",
    "\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(value, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "            ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'cv_stability.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CROSS-VALIDATION STABILITY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mean Accuracy:        {mean_accuracy:.3f}\")\n",
    "print(f\"Standard Deviation:   {std_accuracy:.3f}\")\n",
    "print(f\"Min Accuracy:         {np.min(fold_scores):.3f}\")\n",
    "print(f\"Max Accuracy:         {np.max(fold_scores):.3f}\")\n",
    "print(f\"Range:                {np.max(fold_scores) - np.min(fold_scores):.3f}\")\n",
    "print(f\"Coefficient of Variation: {std_accuracy / mean_accuracy:.3f}\")\n",
    "print(f\"{'=' * 70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddd523",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECODING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nParticipant: {subject}, Session: {session}\")\n",
    "print(f\"Task: {task}\")\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(f\"Number of electrodes (conditions): {n_conditions}\")\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "\n",
    "print(\"\\nCLASSIFIER SETUP:\")\n",
    "print(\"  Model: Support Vector Classifier (Linear kernel)\")\n",
    "print(\"  Feature standardization: Z-score (per sample)\")\n",
    "print(\"  Feature selection: 20th percentile screening\")\n",
    "print(\"  CV: Leave-one-run-out\")\n",
    "\n",
    "print(\"\\nRESULTS (Out-of-fold CV):\")\n",
    "print(f\"  Mean Decoding Accuracy: {mean_accuracy:.3f} ({mean_accuracy*100:.1f}%)\")\n",
    "print(f\"  Chance Level: {chance_level:.3f} ({chance_level*100:.1f}%)\")\n",
    "print(f\"  Balanced Accuracy: {balanced_accuracy_score(y, y_pred):.3f}\")\n",
    "print(\"  Statistical Significance: p < 0.001 ***\" if p_value.pvalue < 0.001 else f\"  Statistical Significance: p = {p_value.pvalue:.3f}\")\n",
    "\n",
    "print(\"\\nCONSISTENCY (across runs):\")\n",
    "print(f\"  Std Dev (folds): {std_accuracy:.3f}\")\n",
    "print(f\"  Min Fold Accuracy: {np.min(fold_scores):.3f}\")\n",
    "print(f\"  Max Fold Accuracy: {np.max(fold_scores):.3f}\")\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "if mean_accuracy > chance_level and p_value.pvalue < 0.05:\n",
    "    print(\"  ✓ Electrode-specific activations are decodable from fMRI above chance\")\n",
    "elif mean_accuracy > chance_level:\n",
    "    print(\"  • Above chance, but not statistically significant\")\n",
    "else:\n",
    "    print(\"  • Near chance; poor decodability\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "log_file.close()\n",
    "print = original_print \n",
    "print(f\"\\n✓ All outputs saved to: {OUTPUT_LOG.resolve()}\")\n",
    "print(f\"✓ All figures saved to: {FIGURES_DIR.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "somatosensory_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
